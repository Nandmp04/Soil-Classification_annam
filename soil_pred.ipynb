{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSkMPSZpSNg-",
        "outputId": "b6ff01b6-eba3-4763-cc55-4d05336de1c1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.5942 - loss: 1.0009 - val_accuracy: 0.3984 - val_loss: 1.1081\n",
            "Epoch 2/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.7470 - loss: 0.6073 - val_accuracy: 0.7236 - val_loss: 0.9368\n",
            "Epoch 3/35\n",
            "35/35 - 39s - 1s/step - accuracy: 0.7989 - loss: 0.5137 - val_accuracy: 0.7642 - val_loss: 0.9567\n",
            "Epoch 4/35\n",
            "35/35 - 48s - 1s/step - accuracy: 0.8298 - loss: 0.4188 - val_accuracy: 0.2683 - val_loss: 1.7079\n",
            "Epoch 5/35\n",
            "35/35 - 75s - 2s/step - accuracy: 0.8717 - loss: 0.3555 - val_accuracy: 0.8780 - val_loss: 0.3810\n",
            "Epoch 6/35\n",
            "35/35 - 42s - 1s/step - accuracy: 0.8954 - loss: 0.3005 - val_accuracy: 0.7561 - val_loss: 1.0487\n",
            "Epoch 7/35\n",
            "35/35 - 37s - 1s/step - accuracy: 0.8981 - loss: 0.2939 - val_accuracy: 0.9106 - val_loss: 0.2522\n",
            "Epoch 8/35\n",
            "35/35 - 39s - 1s/step - accuracy: 0.9263 - loss: 0.1991 - val_accuracy: 0.9350 - val_loss: 0.1781\n",
            "Epoch 9/35\n",
            "35/35 - 37s - 1s/step - accuracy: 0.9390 - loss: 0.1767 - val_accuracy: 0.8537 - val_loss: 0.5819\n",
            "Epoch 10/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.9381 - loss: 0.1863 - val_accuracy: 0.8293 - val_loss: 0.5925\n",
            "Epoch 11/35\n",
            "35/35 - 42s - 1s/step - accuracy: 0.9609 - loss: 0.1139 - val_accuracy: 0.8943 - val_loss: 0.4221\n",
            "Epoch 12/35\n",
            "35/35 - 39s - 1s/step - accuracy: 0.9718 - loss: 0.0870 - val_accuracy: 0.9024 - val_loss: 0.4002\n",
            "Epoch 13/35\n",
            "35/35 - 37s - 1s/step - accuracy: 0.9672 - loss: 0.0929 - val_accuracy: 0.8862 - val_loss: 0.3526\n",
            "Epoch 14/35\n",
            "35/35 - 35s - 1s/step - accuracy: 0.9754 - loss: 0.0654 - val_accuracy: 0.9187 - val_loss: 0.3186\n",
            "Epoch 15/35\n",
            "35/35 - 43s - 1s/step - accuracy: 0.9800 - loss: 0.0661 - val_accuracy: 0.8699 - val_loss: 0.6218\n",
            "Epoch 16/35\n",
            "35/35 - 36s - 1s/step - accuracy: 0.9818 - loss: 0.0537 - val_accuracy: 0.8537 - val_loss: 0.8106\n",
            "Epoch 17/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.9745 - loss: 0.0887 - val_accuracy: 0.8293 - val_loss: 0.6153\n",
            "Epoch 18/35\n",
            "35/35 - 41s - 1s/step - accuracy: 0.9791 - loss: 0.0651 - val_accuracy: 0.9106 - val_loss: 0.2578\n",
            "Epoch 19/35\n",
            "35/35 - 48s - 1s/step - accuracy: 0.9836 - loss: 0.0526 - val_accuracy: 0.8943 - val_loss: 0.4388\n",
            "Epoch 20/35\n",
            "35/35 - 75s - 2s/step - accuracy: 0.9864 - loss: 0.0505 - val_accuracy: 0.7561 - val_loss: 1.1403\n",
            "Epoch 21/35\n",
            "35/35 - 42s - 1s/step - accuracy: 0.9845 - loss: 0.0487 - val_accuracy: 0.8618 - val_loss: 0.8291\n",
            "Epoch 22/35\n",
            "35/35 - 43s - 1s/step - accuracy: 0.9773 - loss: 0.0593 - val_accuracy: 0.9187 - val_loss: 0.2618\n",
            "Epoch 23/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.9791 - loss: 0.0688 - val_accuracy: 0.8699 - val_loss: 0.7272\n",
            "Epoch 24/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.9818 - loss: 0.0718 - val_accuracy: 0.6667 - val_loss: 1.5467\n",
            "Epoch 25/35\n",
            "35/35 - 37s - 1s/step - accuracy: 0.9463 - loss: 0.1899 - val_accuracy: 0.8618 - val_loss: 0.4889\n",
            "Epoch 26/35\n",
            "35/35 - 43s - 1s/step - accuracy: 0.9809 - loss: 0.0617 - val_accuracy: 0.8293 - val_loss: 0.8213\n",
            "Epoch 27/35\n",
            "35/35 - 35s - 1s/step - accuracy: 0.9873 - loss: 0.0359 - val_accuracy: 0.8618 - val_loss: 0.6604\n",
            "Epoch 28/35\n",
            "35/35 - 41s - 1s/step - accuracy: 0.9818 - loss: 0.0444 - val_accuracy: 0.8537 - val_loss: 0.7036\n",
            "Epoch 29/35\n",
            "35/35 - 42s - 1s/step - accuracy: 0.9927 - loss: 0.0184 - val_accuracy: 0.8943 - val_loss: 0.4851\n",
            "Epoch 30/35\n",
            "35/35 - 35s - 1s/step - accuracy: 0.9955 - loss: 0.0189 - val_accuracy: 0.8618 - val_loss: 0.6779\n",
            "Epoch 31/35\n",
            "35/35 - 41s - 1s/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.8780 - val_loss: 0.7608\n",
            "Epoch 32/35\n",
            "35/35 - 41s - 1s/step - accuracy: 0.9955 - loss: 0.0121 - val_accuracy: 0.9512 - val_loss: 0.3184\n",
            "Epoch 33/35\n",
            "35/35 - 46s - 1s/step - accuracy: 0.9918 - loss: 0.0271 - val_accuracy: 0.9024 - val_loss: 0.5003\n",
            "Epoch 34/35\n",
            "35/35 - 40s - 1s/step - accuracy: 0.9973 - loss: 0.0103 - val_accuracy: 0.8618 - val_loss: 0.8266\n",
            "Epoch 35/35\n",
            "35/35 - 37s - 1s/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.8862 - val_loss: 0.6952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved at /content/soil_model.h5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Paths\n",
        "csv_path     = '/content/drive/MyDrive/soil_classification/train_labels.csv'\n",
        "image_folder = '/content/drive/MyDrive/soil_classification/train'\n",
        "\n",
        "# 2. Load labels CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(image_folder, x))\n",
        "\n",
        "# 3. Encode soil_type → integer labels\n",
        "soil_types = sorted(df['soil_type'].unique())   # ['alluvial','black','clay','red']\n",
        "label_map  = {soil:i for i,soil in enumerate(soil_types)}\n",
        "df['label'] = df['soil_type'].map(label_map)\n",
        "\n",
        "# 4. Image preprocessing\n",
        "IMG_H, IMG_W = 224, 224\n",
        "\n",
        "def preprocess_image(path):\n",
        "    img = load_img(path, target_size=(IMG_H, IMG_W))\n",
        "    arr = img_to_array(img) / 255.0\n",
        "    return arr\n",
        "\n",
        "def build_dataset(df):\n",
        "    X = np.stack([preprocess_image(p) for p in df['image_path']])\n",
        "    y = df['label'].values\n",
        "    return X, y\n",
        "\n",
        "X, y = build_dataset(df)\n",
        "y_cat = to_categorical(y, num_classes=len(soil_types))\n",
        "\n",
        "# 5. Build model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_H, IMG_W, 3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(soil_types), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. Train\n",
        "model.fit(X, y_cat,\n",
        "          epochs=35,\n",
        "          batch_size=32,\n",
        "          validation_split=0.1,\n",
        "          verbose=2)\n",
        "\n",
        "# 7. Save model\n",
        "model.save('/content/soil_model.h5')\n",
        "print(\"✅ Model saved at /content/soil_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# --- Load the trained model ---\n",
        "model = load_model('/content/soil_model.h5')\n",
        "print(\"✅ Model loaded.\")\n",
        "\n",
        "# --- Constants ---\n",
        "IMG_H, IMG_W = 128, 128\n",
        "soil_types = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
        "label_map = {i: s for i, s in enumerate(soil_types)}\n",
        "\n",
        "# --- Test images folder ---\n",
        "test_folder = '/content/drive/MyDrive/soil_classification/test'\n",
        "\n",
        "# --- Prediction function ---\n",
        "def predict_soil_type(image_path):\n",
        "    img = load_img(image_path, target_size=(IMG_H, IMG_W))\n",
        "    arr = img_to_array(img) / 255.0\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    pred = np.argmax(model.predict(arr, verbose=0), axis=1)[0]\n",
        "    return label_map[pred]\n",
        "\n",
        "# --- Predict and store results ---\n",
        "results = []\n",
        "\n",
        "for filename in sorted(os.listdir(test_folder)):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png','.gif','.webp')):\n",
        "        path = os.path.join(test_folder, filename)\n",
        "        pred = predict_soil_type(path)\n",
        "        results.append({'image_id': filename, 'soil_type': pred})\n",
        "\n",
        "# --- Save to CSV ---\n",
        "output_df = pd.DataFrame(results)\n",
        "csv_output_path = '/content/predictions.csv'\n",
        "output_df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "print(f\"✅ Predictions saved to {csv_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiBNjvBQtz6A",
        "outputId": "cc1fd22f-893a-499f-dcfe-746f75c85db0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded.\n",
            "✅ Predictions saved to /content/predictions.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}